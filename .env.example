# RepoInsight Environment Variables

# Database
DATABASE_URL=sqlite:///./repoinsight.db

# Celery/Redis
CELERY_BROKER_URL=redis://localhost:6379/0
CELERY_RESULT_BACKEND=redis://localhost:6379/0

# Frontend
FRONTEND_ORIGIN=http://localhost:3000

# Local LLM Model Path (REQUIRED)
# Download a recommended model from HuggingFace:
# - Llama 3.2 1B (Recommended, ~750MB): https://huggingface.co/bartowski/Llama-3.2-1B-Instruct-GGUF
#   Download file: Llama-3.2-1B-Instruct-Q4_K_M.gguf
# - Qwen2.5-Coder 1.5B (~1GB): https://huggingface.co/Qwen/Qwen2.5-Coder-1.5B-Instruct-GGUF
#   Download file: qwen2.5-coder-1.5b-instruct-q4_k_m.gguf
# - Phi-3 Mini 3.8B (~2.2GB): https://huggingface.co/microsoft/Phi-3-mini-4k-instruct-gguf
#   Download file: Phi-3-mini-4k-instruct-q4.gguf
#
# Save the downloaded .gguf file to ./models/ directory and set the path below:
LOCAL_MODEL_PATH=./models/Llama-3.2-1B-Instruct-Q4_K_M.gguf

# LLM Service (Docker)
LLM_SERVICE_URL=http://localhost:8080
