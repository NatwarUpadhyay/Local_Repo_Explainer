# ğŸš€ LocalRepoExplainer - Quick Start Guide

## ğŸ¯ Get Started in 5 Minutes

LocalRepoExplainer is a complete, privacy-first code analysis tool with local AI. Follow these steps to start analyzing code.

---

## âš¡ Quick Start (PowerShell - Windows)

### Step 1: One-Time Setup

```powershell
# Clone the repository
git clone <repo-url>
cd LocalRepoExplainer

# Run setup script (installs dependencies, downloads model)
.\setup_venv.ps1
```

This will:
- âœ… Create Python virtual environment
- âœ… Install all backend dependencies
- âœ… Install all frontend dependencies
- âœ… Download Llama 3.2 1B model (~760 MB)

### Step 2: Start All Services

```powershell
# Start backend, worker, and frontend
.\run.ps1
```

This opens 3 terminal windows:
- ğŸ”§ Backend API (port 8000)
- âš™ï¸ Celery Worker
- ğŸ¨ Frontend (port 3000)

### Step 3: Access the Application

Open your browser to: **http://localhost:3000**

---

## ğŸŒ Application URLs

- **Web UI:** http://localhost:3000
- **API Docs:** http://localhost:8000/docs
- **Health Check:** http://localhost:8000/health

---

## ğŸ“– How to Use

### 1. Select or Upload a Model

**Option A: Use Pre-configured Model**
- Select from 9 recommended models (Llama, Qwen, DeepSeek, etc.)
- Click the download link
- Upload the downloaded .gguf file

**Option B: Use Downloaded Model**
- If you ran `setup_venv.ps1`, Llama 3.2 1B is already downloaded
- Click "Upload Your Own Model"
- Select: `models/Llama-3.2-1B-Instruct-Q4_K_M.gguf`

### 2. Provide Code to Analyze

**Option A: GitHub URL**
- Paste any public GitHub repository URL
- Example: `https://github.com/fastapi/fastapi`

**Option B: File Upload**
- Drag and drop a .zip or .tar.gz file
- Or click "Browse" to select

### 3. Start Analysis

- Click "Analyze Repository"
- Watch real-time progress (4 stages)
- Analysis takes 15-60 seconds depending on repo size

### 4. Explore Results

**Tree View:**
- See hierarchical structure
- Click "Analyze Locally" on any component
- View AI-generated insights
- Check security vulnerabilities (red box)

**Graph View:**
- Interactive dependency visualization
- Click nodes to explore
- Use filters (Repository/Directory/File)
- Pan, zoom, and navigate

**Chat:**
- Ask questions about the codebase
- Get AI-powered answers
- Uses your local LLM

---

## âœ… Currently Implemented Features

### Agentic AI Pipeline
- âœ… **Local LLM Agents** - 9+ autonomous model options with CoT reasoning
- âœ… **Multi-Agent Architecture** - Parser â†’ Analyzer â†’ Generator pipeline
- âœ… **Intelligent Orchestration** - Celery workers with autonomous task distribution
- âœ… **Chain-of-Thought Analysis** - Step-by-step reasoning for architecture understanding

### Code Intelligence
- âœ… **Autonomous Language Detection** - AI-driven parsing for 20+ languages (Python, JS, TS, Java, Go, Rust, C#, C++)
- âœ… **Dual Visualization** - Tree View + Graph View with intelligent layout
- âœ… **AI Chat Interface** - Conversational agent for codebase Q&A
- âœ… **Real-Time Progress** - Live agent pipeline status tracking
- âœ… **Smart Model Selection** - Upload or choose pre-configured AI models
- âœ… **Repository Analysis** - GitHub URL or local upload with automated processing
- âœ… **Modern UI** - Dark theme with fluid animations

## ğŸ”® Future Enhancements

The features below are **not yet implemented**. See `PROJECT_REFERENCE.md` for detailed implementation roadmaps:

- ğŸ”® Multi-Level Graphs (Package â†’ Module â†’ Class drill-down)
- ğŸ”® GraphQL API for flexible querying
- ğŸ”® Vulnerability Scanning with security reports
- ğŸ”® Export Results (JSON, SVG, PNG, PDF, HTML)
- ğŸ”® Enterprise Auth (OAuth2/JWT, RBAC, audit logs)
- ğŸ”® Performance Optimization for 100K+ LOC
- ğŸ”® Prometheus/Grafana monitoring integration

---

## ğŸ› ï¸ Manual Setup (Alternative)

If `setup_venv.ps1` doesn't work:

### Install Dependencies

```powershell
# Create virtual environment
python -m venv venv
.\venv\Scripts\Activate.ps1

# Install backend
pip install -r backend\requirements.txt
pip install -r worker\requirements.txt

# Install frontend
cd frontend
npm install
cd ..
```

### Download Model

```powershell
python download_model.py
```

### Start Services Manually

```powershell
# Terminal 1: Backend API
.\venv\Scripts\python.exe -m uvicorn backend.app.main:app --reload --port 8000

# Terminal 2: Celery Worker
.\venv\Scripts\python.exe -m celery -A backend.app.worker worker --loglevel=info -P solo

# Terminal 3: Frontend
cd frontend
npm run dev
```

---

## ğŸ“ Example Repositories to Try

**Small (Fast - ~15 seconds):**
- https://github.com/psf/requests
- https://github.com/pallets/flask

**Medium (~30 seconds):**
- https://github.com/fastapi/fastapi
- https://github.com/django/django

**Large (~60 seconds):**
- https://github.com/python/cpython
- https://github.com/tensorflow/tensorflow

---

## ğŸ”§ Troubleshooting

### Services Won't Start

```powershell
# Kill existing processes
taskkill /F /IM python.exe /T
taskkill /F /IM node.exe /T

# Restart
.\run.ps1
```

### Model Not Found

```powershell
# Download model
python download_model.py

# Check it exists
dir models\
```

### Redis Connection Error

```powershell
# Install Redis (if not installed)
choco install redis-64

# Start Redis
redis-server
```

### Frontend Won't Load

```powershell
cd frontend
Remove-Item -Recurse -Force .next
npm run dev
```

---

## ğŸ“š Next Steps

- **Full Documentation:** See `PROJECT_REFERENCE.md`
- **Getting Started Guide:** See `START_HERE.md`
- **Architecture Details:** Check backend/frontend code

---

## ğŸ’¡ Tips

- **First analysis slower:** Model loads into memory (~5-10 seconds)
- **Subsequent analyses faster:** Model stays in memory
- **Large repos:** May take 60+ seconds for 100k+ lines
- **System requirements:** 4GB RAM minimum, 8GB recommended

---

**ğŸ‰ You're ready to analyze code! Open http://localhost:3000 and start exploring.**
3. **Click "Analyze Repository"**
   - The system will create a job
   - You'll see real-time status updates
   - Progress bar shows the analysis stages

4. **View Results**
   - When complete, the dependency graph will be displayed
   - See files, components, and their relationships
   - Interactive visualization (ready for enhancement)

### Using the API Directly

```powershell
# Create a new analysis job
Invoke-RestMethod -Uri "http://localhost:8000/api/v1/jobs/" `
  -Method POST `
  -ContentType "application/json" `
  -Body '{"repo_url":"https://github.com/fastapi/fastapi","source_type":"git"}'

# Get job status (replace JOB_ID)
Invoke-RestMethod -Uri "http://localhost:8000/api/v1/jobs/JOB_ID" `
  -Method GET

# Get graph results (when completed)
Invoke-RestMethod -Uri "http://localhost:8000/api/v1/jobs/JOB_ID/graph" `
  -Method GET
```

---

## ğŸ“‹ Current Capabilities

### âœ… **Fully Implemented**
- Modern, responsive web interface
- Job creation and management API
- Real-time status tracking with progress indicators
- Background task processing with Celery
- Database persistence with SQLModel
- Docker containerization for all services
- Health checks and monitoring endpoints
- Error handling and validation

### ğŸ”„ **Simulated (Ready for Implementation)**
- Repository cloning
- Code parsing and analysis
- Dependency graph generation
- LLM-powered explanations

The infrastructure is **production-ready**. The analysis logic is currently simulated, which means the worker processes jobs through all stages and returns a placeholder graph structure.

---

## ğŸ› ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Frontend (Next.js)                             â”‚
â”‚  http://localhost:3000                          â”‚
â”‚  - Modern React UI with TypeScript              â”‚
â”‚  - Real-time status polling                     â”‚
â”‚  - Graph visualization                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â”‚ HTTP/REST
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  API Server (FastAPI)                           â”‚
â”‚  http://localhost:8000                          â”‚
â”‚  - Job creation & retrieval                     â”‚
â”‚  - Status endpoints                             â”‚
â”‚  - Graph data API                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â”‚ Celery Tasks
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Message Queue (Redis)                          â”‚
â”‚  localhost:6379                                 â”‚
â”‚  - Task distribution                            â”‚
â”‚  - Result backend                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Celery Worker                                  â”‚
â”‚  - Processes analysis jobs                      â”‚
â”‚  - Updates job status                           â”‚
â”‚  - Generates results                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Database (SQLite in Docker Volume)             â”‚
â”‚  - Job records                                  â”‚
â”‚  - Status tracking                              â”‚
â”‚  - Result storage                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ Project Structure

```
LocalRepoExplainer/
â”œâ”€â”€ backend/                  # Python FastAPI backend
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ api/             # API endpoints
â”‚   â”‚   â”œâ”€â”€ models.py        # SQLModel database models
â”‚   â”‚   â”œâ”€â”€ database.py      # Database configuration
â”‚   â”‚   â”œâ”€â”€ worker.py        # Celery worker & tasks
â”‚   â”‚   â””â”€â”€ main.py          # FastAPI app
â”‚   â”œâ”€â”€ tests/               # Backend tests
â”‚   â””â”€â”€ requirements.txt     # Python dependencies
â”œâ”€â”€ frontend/                 # Next.js frontend
â”‚   â”œâ”€â”€ app/                 # Next.js 13+ app directory
â”‚   â”‚   â”œâ”€â”€ page.tsx         # Main page with form
â”‚   â”‚   â””â”€â”€ layout.tsx       # Root layout
â”‚   â”œâ”€â”€ components/          # React components
â”‚   â”‚   â””â”€â”€ GraphExplorer.tsx # Graph visualization
â”‚   â””â”€â”€ package.json         # Node dependencies
â”œâ”€â”€ docker-compose.yml       # Service orchestration
â”œâ”€â”€ Dockerfile.api           # API container image
â”œâ”€â”€ Dockerfile.worker        # Worker container image
â””â”€â”€ Dockerfile.llm           # LLM service (optional)
```

---

## ğŸ› Troubleshooting

### Services won't start
```powershell
# Check Docker is running
docker --version

# Stop and remove all containers
docker compose down

# Rebuild and start
docker compose up --build -d api worker redis frontend
```

### Frontend shows connection errors
```powershell
# Check if API is running
docker compose ps

# View API logs
docker compose logs api

# Restart API
docker compose restart api
```

### Worker not processing jobs
```powershell
# Check worker logs
docker compose logs worker

# Restart worker
docker compose restart worker

# Check Redis is running
docker compose ps redis
```

### Database errors
```powershell
# Stop services
docker compose down

# Remove database volume
docker volume rm localrepoexplainer_db_data

# Restart (will create fresh database)
docker compose up -d
```

---

## ğŸ”® Next Steps (When Ready to Add Analysis)

To implement actual code analysis, you'll need to enhance the worker (`backend/app/worker.py`):

1. **Add repository cloning:**
   ```python
   import subprocess
   subprocess.run(["git", "clone", repo_url, "/tmp/repo"])
   ```

2. **Add file parsing:**
   ```python
   import ast  # For Python
   # Parse files and extract imports, classes, functions
   ```

3. **Build dependency graph:**
   ```python
   # Create nodes for files, classes, functions
   # Create edges for imports, calls, inheritance
   ```

4. **Connect to LLM service** (optional):
   ```python
   # Send code snippets to LLM for explanations
   ```

The infrastructure is ready and waiting for these enhancements!

---

## ğŸ“ Support

If you encounter issues:

1. Check the logs: `docker compose logs -f [service-name]`
2. Verify all services are running: `docker compose ps`
3. Restart services: `docker compose restart`
4. Rebuild if needed: `docker compose up --build -d`

---

## ğŸ“ Learning Resources

- **FastAPI:** https://fastapi.tiangolo.com/
- **Celery:** https://docs.celeryq.dev/
- **Next.js:** https://nextjs.org/docs
- **Docker Compose:** https://docs.docker.com/compose/

---

**ğŸ‰ Enjoy your RepoInsight application!**

The foundation is solid, the UI is beautiful, and it's ready for the code analysis logic to be implemented when you're ready.
